# scripts/init_knowledge_base.py
"""
CSV íŒŒì¼ë¡œë¶€í„° ì§€ì‹ë² ì´ìŠ¤ ì´ˆê¸°í™”
ì‚¬ìš©ë²•: python scripts/init_knowledge_base.py --csv-file data/faq.csv
"""

import os
import sys
import pandas as pd
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.embeddings.embedding import Embedder
from app.vector.chroma_store import ChromaStore
from app.core.logging_config import get_logger

logger = get_logger(__name__)


def load_csv_faq(csv_path: str) -> List[Dict[str, Any]]:
    """
    CSV íŒŒì¼ì—ì„œ FAQ ë°ì´í„° ë¡œë“œ

    Args:
        csv_path: CSV íŒŒì¼ ê²½ë¡œ

    Returns:
        List[Dict]: íŒŒì‹±ëœ FAQ ë°ì´í„°
    """
    try:
        df = pd.read_csv(csv_path, encoding='utf-8')

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_cols = ['question', 'answer']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")

        # ë°ì´í„° ì •ì œ ë° ë³€í™˜
        faq_data = []
        for idx, row in df.iterrows():
            question = str(row['question']).strip()
            answer = str(row['answer']).strip()
            keywords = str(row.get('keywords', '')).strip()

            # ë¹ˆ ë°ì´í„° ìŠ¤í‚µ
            if not question or not answer or question == 'nan' or answer == 'nan':
                logger.warning(f"í–‰ {idx + 2}: ë¹ˆ ì§ˆë¬¸/ë‹µë³€ ìŠ¤í‚µ")
                continue

            # í‚¤ì›Œë“œ íŒŒì‹± (ì„¸ë¯¸ì½œë¡  êµ¬ë¶„)
            tag_list = []
            if keywords and keywords != 'nan':
                tag_list = [kw.strip() for kw in keywords.split(';') if kw.strip()]

            faq_data.append({
                'question': question,
                'answer': answer,
                'keywords': tag_list,
                'source': 'csv_init',
                'category': 'ê¸°ë³¸FAQ'
            })

        logger.info(f"CSVì—ì„œ {len(faq_data)}ê°œ FAQ ë¡œë“œ ì™„ë£Œ")
        return faq_data

    except Exception as e:
        logger.error(f"CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise


def embed_and_store_faqs(faq_data: List[Dict[str, Any]],
                         embedder: Embedder,
                         store: ChromaStore,
                         batch_size: int = 10) -> None:
    """
    FAQ ë°ì´í„°ë¥¼ ì„ë² ë”©í•˜ì—¬ ë²¡í„°DBì— ì €ì¥

    Args:
        faq_data: FAQ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        embedder: ì„ë² ë”© ê°ì²´
        store: ë²¡í„° ì €ì¥ì†Œ
        batch_size: ë°°ì¹˜ í¬ê¸°
    """
    try:
        total_count = len(faq_data)
        logger.info(f"ì´ {total_count}ê°œ FAQ ì„ë² ë”© ì‹œì‘...")

        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        for i in range(0, total_count, batch_size):
            batch = faq_data[i:i + batch_size]

            # ë¬¸ì„œ í…ìŠ¤íŠ¸ ìƒì„± (Q&A í˜•íƒœë¡œ ê²°í•©)
            documents = []
            metadatas = []

            for item in batch:
                # FAQ ë¬¸ì„œ í˜•íƒœë¡œ í¬ë§·
                doc_text = f"Q: {item['question']}\nA: {item['answer']}"
                documents.append(doc_text)

                # ë©”íƒ€ë°ì´í„° êµ¬ì„±
                metadata = {
                    'source': item['source'],
                    'category': item['category'],
                    'tags': ';'.join(item['keywords']),
                    'timestamp': datetime.now().isoformat(),
                    'question': item['question'],  # ê²€ìƒ‰ í¸ì˜ì„±ì„ ìœ„í•´ ì¶”ê°€
                }
                metadatas.append(metadata)

            # ì„ë² ë”© ìƒì„±
            logger.info(f"ë°°ì¹˜ {i // batch_size + 1}/{(total_count - 1) // batch_size + 1} ì„ë² ë”© ì¤‘...")
            embeddings = embedder.embed(documents)

            # ë²¡í„°DBì— ì €ì¥
            store.add_docs(
                contents=documents,
                metadatas=metadatas,
                embeddings=embeddings,
                ids=None  # UUID ìë™ ìƒì„±
            )

            logger.info(f"ë°°ì¹˜ ì™„ë£Œ: {len(batch)}ê°œ FAQ ì €ì¥")

        logger.info(f"âœ… ì „ì²´ {total_count}ê°œ FAQ ì´ˆê¸°í™” ì™„ë£Œ!")

    except Exception as e:
        logger.error(f"ì„ë² ë”©/ì €ì¥ ì‹¤íŒ¨: {e}")
        raise


def check_existing_data(store: ChromaStore) -> int:
    """ê¸°ì¡´ ë°ì´í„° í™•ì¸"""
    try:
        # ChromaDBì—ì„œ ì „ì²´ ë¬¸ì„œ ìˆ˜ í™•ì¸
        collection_info = store.collection.count()
        return collection_info
    except Exception:
        return 0


def main():
    parser = argparse.ArgumentParser(description='CSVì—ì„œ ì§€ì‹ë² ì´ìŠ¤ ì´ˆê¸°í™”')
    parser.add_argument('--csv-file', required=True, help='FAQ CSV íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--force', action='store_true', help='ê¸°ì¡´ ë°ì´í„°ê°€ ìˆì–´ë„ ê°•ì œ ì‹¤í–‰')
    parser.add_argument('--batch-size', type=int, default=10, help='ì„ë² ë”© ë°°ì¹˜ í¬ê¸°')

    args = parser.parse_args()

    try:
        # CSV íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not Path(args.csv_file).exists():
            raise FileNotFoundError(f"CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.csv_file}")

        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        logger.info("ğŸš€ ì§€ì‹ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹œì‘...")
        embedder = Embedder()
        store = ChromaStore()

        # ê¸°ì¡´ ë°ì´í„° í™•ì¸
        existing_count = check_existing_data(store)
        if existing_count > 0 and not args.force:
            logger.warning(f"âš ï¸ ê¸°ì¡´ ë°ì´í„° {existing_count}ê°œ ë°œê²¬. --force ì˜µì…˜ìœ¼ë¡œ ê°•ì œ ì‹¤í–‰ ê°€ëŠ¥")
            return

        if existing_count > 0:
            logger.info(f"ê¸°ì¡´ ë°ì´í„° {existing_count}ê°œ ìœ„ì— ì¶”ê°€ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.")

        # CSV ë¡œë“œ
        faq_data = load_csv_faq(args.csv_file)

        if not faq_data:
            logger.error("ë¡œë“œí•  FAQ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì„ë² ë”© ë° ì €ì¥
        embed_and_store_faqs(faq_data, embedder, store, args.batch_size)

        # ìµœì¢… í™•ì¸
        final_count = check_existing_data(store)
        logger.info(f"ğŸ‰ ì´ˆê¸°í™” ì™„ë£Œ! ì´ {final_count}ê°œ ë¬¸ì„œê°€ ì§€ì‹ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰
        logger.info("ğŸ“ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰...")
        test_question = "íƒœì–‘ê´‘ íŒ¨ë„ ì„±ëŠ¥ì€ ì–´ë–»ê²Œ ì¸¡ì •í•˜ë‚˜ìš”?"
        test_embedding = embedder.embed([test_question])[0]
        results = store.query(test_embedding, k=3)

        if results:
            logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ! {len(results)}ê°œ ìœ ì‚¬ ë¬¸ì„œ ë°œê²¬")
            logger.info(f"ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ê±°ë¦¬: {results[0]['distance']:.3f}")
        else:
            logger.warning("âš ï¸ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ì—ì„œ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()