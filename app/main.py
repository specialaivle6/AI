from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from contextlib import asynccontextmanager
import uvicorn
import time
from typing import Optional, List, Union
import asyncio
from datetime import datetime

# === (ADD) Chatbot wiring imports ===
from app.api import chat as chat_router
from app.services import rag

# Í∞úÏÑ†Îêú ÏûÑÌè¨Ìä∏
from app.core.config import settings, validate_settings
from app.core.exceptions import (
    AIServiceException, ModelNotLoadedException,
    get_http_status_code, EXCEPTION_STATUS_MAPPING
)
from app.core.logging_config import setup_logging, get_logger, log_api_request, log_model_status

from app.services.damage_analyzer import DamageAnalyzer

from app.services.performance_analyzer import PerformanceAnalyzer
from app.models.schemas import (
    DamageAnalysisRequest,
    DamageAnalysisResponse,
    HealthCheckResponse,
    PanelRequest,
    PerformanceReportResponse,
    PerformanceReportDetailResponse,
    PerformanceAnalysisResult
)
from app.utils.image_utils import download_image_from_s3, get_image_info
from app.utils.report_generator import generate_performance_report
from app.utils.performance_utils import estimate_panel_cost

# Î°úÍπÖ Ï¥àÍ∏∞Ìôî
setup_logging()
logger = get_logger(__name__)

# Ï†ÑÏó≠ Î≥ÄÏàòÎ°ú ÏÑúÎπÑÏä§Îì§ Í¥ÄÎ¶¨
damage_analyzer: Optional[DamageAnalyzer] = None
performance_analyzer: Optional[PerformanceAnalyzer] = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Ïï± ÏÉùÎ™ÖÏ£ºÍ∏∞ Í¥ÄÎ¶¨"""
    global damage_analyzer, performance_analyzer

    # Startup
    logger.info(f"üöÄ {settings.app_name} v{settings.app_version} Ï¥àÍ∏∞Ìôî ÏãúÏûë...")

    # ÏÑ§Ï†ï Í≤ÄÏ¶ù
    config_issues = validate_settings()
    if config_issues:
        logger.warning("‚ö†Ô∏è ÏÑ§Ï†ï Í≤ÄÏ¶ù Í≤∞Í≥º:")
        for issue in config_issues:
            logger.warning(f"  - {issue}")

    try:
        # ÏÜêÏÉÅ Î∂ÑÏÑùÍ∏∞ Ï¥àÍ∏∞Ìôî
        log_model_status("DamageAnalyzer", "loading", path=settings.damage_model_path)
        damage_analyzer = DamageAnalyzer()
        await damage_analyzer.initialize()
        log_model_status("DamageAnalyzer", "loaded",
                        loaded=damage_analyzer.is_loaded())

        # ÏÑ±Îä• Î∂ÑÏÑùÍ∏∞ Ï¥àÍ∏∞Ìôî
        log_model_status("PerformanceAnalyzer", "loading", path=settings.performance_model_path)
        performance_analyzer = PerformanceAnalyzer()
        await performance_analyzer.initialize()
        log_model_status("PerformanceAnalyzer", "loaded",
                        loaded=performance_analyzer.is_loaded())

        # === (ADD) Chatbot RAG warmup ===
        try:
            rag.warmup()
            logger.info("ü§ñ Chatbot RAG warmup ÏôÑÎ£å")
        except Exception as e:
            logger.warning(f"ü§ñ Chatbot RAG warmup Í±¥ÎÑàÎúÄ: {e}")

        logger.info("‚úÖ AI ÏÑúÎπÑÏä§ Ï§ÄÎπÑ ÏôÑÎ£å!")

    except Exception as e:
        logger.error(f"‚ùå ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
        raise

    yield

    # Shutdown
    logger.info("üîÑ AI ÏÑúÎπÑÏä§ Ï¢ÖÎ£å Ï§ë...")


# FastAPI Ïï± ÏÉùÏÑ± (Í∞úÏÑ†Îêú ÏÑ§Ï†ï ÏÇ¨Ïö©)
app = FastAPI(
    title=settings.app_name,
    description=settings.description,
    version=settings.app_version,
    lifespan=lifespan
)

# CORS ÏÑ§Ï†ï (ÏÑ§Ï†ï ÌååÏùºÏóêÏÑú Í∞ÄÏ†∏Ïò§Í∏∞)
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins,
    allow_credentials=settings.cors_credentials,
    allow_methods=["*"],
    allow_headers=["*"],
)

# === (ADD) Chatbot router mount ===
app.include_router(chat_router.router)


# Ï†ÑÏó≠ ÏòàÏô∏ Ï≤òÎ¶¨Í∏∞
@app.exception_handler(AIServiceException)
async def ai_service_exception_handler(request: Request, exc: AIServiceException):
    """AI ÏÑúÎπÑÏä§ Ïª§Ïä§ÌÖÄ ÏòàÏô∏ Ï≤òÎ¶¨"""
    logger.error(f"AI Service Error: {exc.message}", extra={"details": exc.details})

    return JSONResponse(
        status_code=get_http_status_code(exc),
        content={
            "error": exc.error_code or "AI_SERVICE_ERROR",
            "message": exc.message,
            "details": exc.details,
            "timestamp": datetime.now().isoformat()
        }
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """ÏùºÎ∞ò ÏòàÏô∏ Ï≤òÎ¶¨"""
    logger.error(f"Unexpected error: {str(exc)}", exc_info=True)

    return JSONResponse(
        status_code=500,
        content={
            "error": "INTERNAL_SERVER_ERROR",
            "message": "ÎÇ¥Î∂Ä ÏÑúÎ≤Ñ Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§",
            "timestamp": datetime.now().isoformat()
        }
    )


def _check_service_health(analyzer, service_name: str) -> dict:
    """ÏÑúÎπÑÏä§ Ìó¨Ïä§Ï≤¥ÌÅ¨ Í≥µÌÜµ Î°úÏßÅ"""
    if analyzer is None:
        return {
            "status": "unhealthy",
            "model_loaded": False,
            "error": f"{service_name} Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏùå"
        }

    is_healthy = analyzer.is_loaded()
    return {
        "status": "healthy" if is_healthy else "unhealthy",
        "model_loaded": is_healthy,
        "error": None if is_healthy else f"{service_name} Î™®Îç∏ Î°úÎìú Ïã§Ìå®"
    }


@app.get("/")
async def root():
    """Í∏∞Î≥∏ ÏóîÎìúÌè¨Ïù∏Ìä∏"""
    return {
        "service": settings.app_name,
        "version": settings.app_version,
        "status": "running",
        "environment": "development" if settings.is_development else "production",
        "models": {
            "damage_analysis": "YOLOv8 Segmentation",
            "performance_prediction": "Voting Ensemble"
        }
    }


@app.get("/api/damage-analysis/health", response_model=HealthCheckResponse)
async def damage_health_check():
    """ÏÜêÏÉÅ Î∂ÑÏÑù ÏÑúÎπÑÏä§ Ìó¨Ïä§Ï≤¥ÌÅ¨"""
    health_info = _check_service_health(damage_analyzer, "DamageAnalyzer")

    return HealthCheckResponse(
        status=health_info["status"],
        model_loaded=health_info["model_loaded"],
        version=settings.app_version,
        model_type="YOLOv8"
    )


@app.post("/api/damage-analysis/analyze", response_model=DamageAnalysisResponse)
async def analyze_panel_damage_from_s3(request: DamageAnalysisRequest):
    """Î∞±ÏóîÎìúÏóêÏÑú ÏöîÏ≤≠Î∞õÏùÄ S3 URLÎ°ú Ìå®ÎÑê ÏÜêÏÉÅ Î∂ÑÏÑù ÏàòÌñâ"""
    start_time = time.time()

    # ÏÑúÎπÑÏä§ ÏÉÅÌÉú ÌôïÏù∏
    if damage_analyzer is None or not damage_analyzer.is_loaded():
        raise ModelNotLoadedException("DamageAnalyzer", settings.damage_model_path)

    try:
        log_api_request("POST", "/api/damage-analysis/analyze",
                       str(request.user_id), request.panel_id)

        # S3ÏóêÏÑú Ïù¥ÎØ∏ÏßÄ Îã§Ïö¥Î°úÎìú
        image_data = await download_image_from_s3(request.panel_imageurl)
        image_info = get_image_info(image_data, request.panel_imageurl)

        # AI Î∂ÑÏÑù ÏàòÌñâ
        analysis_result = await damage_analyzer.analyze_damage(image_data)
        processing_time = time.time() - start_time

        # ÏùëÎãµ Íµ¨ÏÑ±
        response = DamageAnalysisResponse(
            panel_id=request.panel_id,
            user_id=request.user_id,
            image_info=image_info,
            damage_analysis=analysis_result["damage_analysis"],
            business_assessment=analysis_result["business_assessment"],
            detection_details=analysis_result["detection_details"],
            confidence_score=analysis_result["confidence_score"],
            processing_time_seconds=processing_time
        )

        log_api_request("POST", "/api/damage-analysis/analyze",
                       str(request.user_id), request.panel_id, processing_time)

        return response

    except AIServiceException:
        raise
    except Exception as e:
        logger.error(f"ÏÜêÏÉÅ Î∂ÑÏÑù Ï§ë ÏòàÏÉÅÏπò Î™ªÌïú Ïò§Î•ò: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Î∂ÑÏÑù Ï≤òÎ¶¨ Ïò§Î•ò: {str(e)}")


@app.get("/api/performance-analysis/health")
async def performance_health_check():
    """ÏÑ±Îä• ÏòàÏ∏° ÏÑúÎπÑÏä§ Ìó¨Ïä§Ï≤¥ÌÅ¨"""
    health_info = _check_service_health(performance_analyzer, "PerformanceAnalyzer")

    return {
        **health_info,
        "service": "performance-analysis",
        "version": settings.app_version
    }


from app.models.schemas import (
    # ...
    PerformanceReportResponse,
    PerformanceReportDetailResponse,
    PerformanceAnalysisResult,
)

# Í∏∞Ï°¥ Ìï®Ïàò ÏãúÍ∑∏ÎãàÏ≤ò/Îç∞ÏΩîÎ†àÏù¥ÌÑ∞ ÍµêÏ≤¥
@app.post(
    "/api/performance-analysis/report",
    response_model=Union[PerformanceReportResponse, List[PerformanceReportResponse]],
)
async def generate_performance_report_endpoint(
    request: Union[PanelRequest, List[PanelRequest]]
):
    """
    ÌÉúÏñëÍ¥ë Ìå®ÎÑê ÏÑ±Îä• ÏòàÏ∏° Î∞è PDF Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±
    Îã®Í±¥ ÎòêÎäî Î∞∞Ïó¥ÏùÑ Î∞õÏïÑ Ï≤òÎ¶¨:
    - Îã®Í±¥(dict) -> Îã®Ïùº PerformanceReportResponse
    - Îã§Í±¥(list) -> PerformanceReportResponse Î¶¨Ïä§Ìä∏
    """
    start_time = time.time()

    if performance_analyzer is None or not performance_analyzer.is_loaded():
        raise ModelNotLoadedException("PerformanceAnalyzer", settings.performance_model_path)

    # --- Î∞∞Ïó¥ Ï≤òÎ¶¨ ---
    if isinstance(request, list):
        # ÎèôÏãúÏÑ± Ï†úÌïú (ÏÑ†ÌÉù) ‚Äî ÏÑ§Ï†ïÍ∞í ÏóÜÏúºÎ©¥ 4
        concurrency = getattr(settings, "batch_max_concurrency", 4)
        sem = asyncio.Semaphore(concurrency)

        async def run_one(p: PanelRequest) -> PerformanceReportResponse:
            async with sem:
                log_api_request("POST", "/api/performance-analysis/report(batch)", p.user_id, p.id)
                result = await performance_analyzer.analyze_with_report(p)
                return PerformanceReportResponse(
                    user_id=p.user_id,
                    address=result["report_path"],
                    created_at=result["created_at"]
                )

        tasks = [run_one(p) for p in request]
        return await asyncio.gather(*tasks)

    # --- Îã®Í±¥ Ï≤òÎ¶¨(Í∏∞Ï°¥ Î°úÏßÅ) ---
    try:
        p: PanelRequest = request
        log_api_request("POST", "/api/performance-analysis/report", p.user_id, p.id)

        analysis_result = await performance_analyzer.analyze_with_report(p)

        processing_time = time.time() - start_time
        log_api_request("POST", "/api/performance-analysis/report",
                       p.user_id, p.id, processing_time)

        return PerformanceReportResponse(
            user_id=p.user_id,
            address=analysis_result["report_path"],
            created_at=analysis_result["created_at"]
        )
    except AIServiceException:
        raise
    except Exception as e:
        logger.error(f"ÏÑ±Îä• Î∂ÑÏÑù Ï§ë ÏòàÏÉÅÏπò Î™ªÌïú Ïò§Î•ò: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ÏÑ±Îä• Î∂ÑÏÑù Ï≤òÎ¶¨ Ïò§Î•ò: {str(e)}")



@app.post(
    "/api/performance-analysis/analyze",
    response_model=Union[PerformanceReportDetailResponse, List[PerformanceReportDetailResponse]],
)
async def analyze_performance_detailed(request: Union[PanelRequest, List[PanelRequest]]):
    """
    ÏÉÅÏÑ∏Ìïú ÏÑ±Îä• Î∂ÑÏÑù (PDF ÏÉùÏÑ± ÏóÜÏù¥ Î∂ÑÏÑù Í≤∞Í≥ºÎßå Î∞òÌôò)
    Îã®Í±¥/Î∞∞Ïπò Î™®Îëê ÏßÄÏõê:
    - Îã®Í±¥ -> PerformanceReportDetailResponse
    - Î∞∞Ïó¥ -> PerformanceReportDetailResponse[]
    """
    start_time = time.time()

    if performance_analyzer is None or not performance_analyzer.is_loaded():
        raise ModelNotLoadedException("PerformanceAnalyzer", settings.performance_model_path)

    # --- Î∞∞Ïó¥ Ï≤òÎ¶¨ ---
    if isinstance(request, list):
        concurrency = getattr(settings, "batch_max_concurrency", 4)
        sem = asyncio.Semaphore(concurrency)

        async def run_one(p: PanelRequest) -> PerformanceReportDetailResponse:
            async with sem:
                log_api_request("POST", "/api/performance-analysis/analyze(batch)", p.user_id, p.id)
                ar = await performance_analyzer.analyze_performance(p)

                perf = PerformanceAnalysisResult(
                    predicted_generation=ar["predicted_generation"],
                    actual_generation=ar["actual_generation"],
                    performance_ratio=ar["performance_ratio"],
                    status=ar["status"],
                    lifespan_months=ar.get("lifespan_months"),
                    estimated_cost=ar.get("estimated_cost")
                )

                return PerformanceReportDetailResponse(
                    user_id=p.user_id,
                    panel_id=p.id,
                    performance_analysis=perf,
                    report_path="",
                    created_at=datetime.now().isoformat(),
                    processing_time_seconds=None,
                    panel_info=ar.get("panel_info", {}),
                    environmental_data=ar.get("environmental_data", {})
                )

        tasks = [run_one(p) for p in request]
        return await asyncio.gather(*tasks)

    # --- Îã®Í±¥ Ï≤òÎ¶¨(Í∏∞Ï°¥ Î°úÏßÅ) ---
    try:
        p: PanelRequest = request
        log_api_request("POST", "/api/performance-analysis/analyze", p.user_id, p.id)
        ar = await performance_analyzer.analyze_performance(p)
        processing_time = time.time() - start_time
        log_api_request("POST", "/api/performance-analysis/analyze",
                       p.user_id, p.id, processing_time)

        perf = PerformanceAnalysisResult(
            predicted_generation=ar["predicted_generation"],
            actual_generation=ar["actual_generation"],
            performance_ratio=ar["performance_ratio"],
            status=ar["status"],
            lifespan_months=ar.get("lifespan_months"),
            estimated_cost=ar.get("estimated_cost")
        )

        return PerformanceReportDetailResponse(
            user_id=p.user_id,
            panel_id=p.id,
            performance_analysis=perf,
            report_path="",
            created_at=datetime.now().isoformat(),
            processing_time_seconds=processing_time,
            panel_info=ar.get("panel_info", {}),
            environmental_data=ar.get("environmental_data", {})
        )

    except AIServiceException:
        raise
    except Exception as e:
        logger.error(f"ÏÉÅÏÑ∏ ÏÑ±Îä• Î∂ÑÏÑù Ï§ë ÏòàÏÉÅÏπò Î™ªÌïú Ïò§Î•ò: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ÏÉÅÏÑ∏ Î∂ÑÏÑù Ï≤òÎ¶¨ Ïò§Î•ò: {str(e)}")
