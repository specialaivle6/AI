from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from contextlib import asynccontextmanager
import uvicorn
import time
from typing import Optional
from datetime import datetime

# ê°œì„ ëœ ì„í¬íŠ¸
from app.core.config import settings, validate_settings
from app.core.exceptions import (
    AIServiceException, ModelNotLoadedException,
    get_http_status_code, EXCEPTION_STATUS_MAPPING
)
from app.core.logging_config import setup_logging, get_logger, log_api_request, log_model_status

from app.services.damage_analyzer import DamageAnalyzer

from app.services.performance_analyzer import PerformanceAnalyzer
from app.models.schemas import (
    DamageAnalysisRequest,
    DamageAnalysisResponse,
    HealthCheckResponse,
    PanelRequest,
    PerformanceReportResponse,
    PerformanceReportDetailResponse,
    PerformanceAnalysisResult
)
from app.utils.image_utils import download_image_from_s3, get_image_info
from app.utils.report_generator import generate_performance_report
from app.utils.performance_utils import estimate_panel_cost

# ë¡œê¹… ì´ˆê¸°í™”
setup_logging()
logger = get_logger(__name__)

# ì „ì—­ ë³€ìˆ˜ë¡œ ì„œë¹„ìŠ¤ë“¤ ê´€ë¦¬
damage_analyzer: Optional[DamageAnalyzer] = None
performance_analyzer: Optional[PerformanceAnalyzer] = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì•± ìƒëª…ì£¼ê¸° ê´€ë¦¬"""
    global damage_analyzer, performance_analyzer

    # Startup
    logger.info(f"ğŸš€ {settings.app_name} v{settings.app_version} ì´ˆê¸°í™” ì‹œì‘...")

    # ì„¤ì • ê²€ì¦
    config_issues = validate_settings()
    if config_issues:
        logger.warning("âš ï¸ ì„¤ì • ê²€ì¦ ê²°ê³¼:")
        for issue in config_issues:
            logger.warning(f"  - {issue}")

    try:
        # ì†ìƒ ë¶„ì„ê¸° ì´ˆê¸°í™”
        log_model_status("DamageAnalyzer", "loading", path=settings.damage_model_path)
        damage_analyzer = DamageAnalyzer()
        await damage_analyzer.initialize()
        log_model_status("DamageAnalyzer", "loaded",
                        loaded=damage_analyzer.is_loaded())

        # ì„±ëŠ¥ ë¶„ì„ê¸° ì´ˆê¸°í™”
        log_model_status("PerformanceAnalyzer", "loading", path=settings.performance_model_path)
        performance_analyzer = PerformanceAnalyzer()
        await performance_analyzer.initialize()
        log_model_status("PerformanceAnalyzer", "loaded",
                        loaded=performance_analyzer.is_loaded())

        logger.info("âœ… AI ì„œë¹„ìŠ¤ ì¤€ë¹„ ì™„ë£Œ!")

    except Exception as e:
        logger.error(f"âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise

    yield

    # Shutdown
    logger.info("ğŸ”„ AI ì„œë¹„ìŠ¤ ì¢…ë£Œ ì¤‘...")


# FastAPI ì•± ìƒì„± (ê°œì„ ëœ ì„¤ì • ì‚¬ìš©)
app = FastAPI(
    title=settings.app_name,
    description=settings.description,
    version=settings.app_version,
    lifespan=lifespan
)

# CORS ì„¤ì • (ì„¤ì • íŒŒì¼ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins,
    allow_credentials=settings.cors_credentials,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ì „ì—­ ì˜ˆì™¸ ì²˜ë¦¬ê¸°
@app.exception_handler(AIServiceException)
async def ai_service_exception_handler(request: Request, exc: AIServiceException):
    """AI ì„œë¹„ìŠ¤ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ì²˜ë¦¬"""
    logger.error(f"AI Service Error: {exc.message}", extra={"details": exc.details})

    return JSONResponse(
        status_code=get_http_status_code(exc),
        content={
            "error": exc.error_code or "AI_SERVICE_ERROR",
            "message": exc.message,
            "details": exc.details,
            "timestamp": datetime.now().isoformat()
        }
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """ì¼ë°˜ ì˜ˆì™¸ ì²˜ë¦¬"""
    logger.error(f"Unexpected error: {str(exc)}", exc_info=True)

    return JSONResponse(
        status_code=500,
        content={
            "error": "INTERNAL_SERVER_ERROR",
            "message": "ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
            "timestamp": datetime.now().isoformat()
        }
    )


def _check_service_health(analyzer, service_name: str) -> dict:
    """ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬ ê³µí†µ ë¡œì§"""
    if analyzer is None:
        return {
            "status": "unhealthy",
            "model_loaded": False,
            "error": f"{service_name} ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ"
        }

    is_healthy = analyzer.is_loaded()
    return {
        "status": "healthy" if is_healthy else "unhealthy",
        "model_loaded": is_healthy,
        "error": None if is_healthy else f"{service_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨"
    }


@app.get("/")
async def root():
    """ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "service": settings.app_name,
        "version": settings.app_version,
        "status": "running",
        "environment": "development" if settings.is_development else "production",
        "models": {
            "damage_analysis": "YOLOv8 Segmentation",
            "performance_prediction": "Voting Ensemble"
        }
    }


@app.get("/api/damage-analysis/health", response_model=HealthCheckResponse)
async def damage_health_check():
    """ì†ìƒ ë¶„ì„ ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬"""
    health_info = _check_service_health(damage_analyzer, "DamageAnalyzer")

    return HealthCheckResponse(
        status=health_info["status"],
        model_loaded=health_info["model_loaded"],
        version=settings.app_version,
        model_type="YOLOv8"
    )


@app.post("/api/damage-analysis/analyze", response_model=DamageAnalysisResponse)
async def analyze_panel_damage_from_s3(request: DamageAnalysisRequest):
    """ë°±ì—”ë“œì—ì„œ ìš”ì²­ë°›ì€ S3 URLë¡œ íŒ¨ë„ ì†ìƒ ë¶„ì„ ìˆ˜í–‰"""
    start_time = time.time()

    # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    if damage_analyzer is None or not damage_analyzer.is_loaded():
        raise ModelNotLoadedException("DamageAnalyzer", settings.damage_model_path)

    try:
        log_api_request("POST", "/api/damage-analysis/analyze",
                       str(request.user_id), request.panel_id)

        # S3ì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        image_data = await download_image_from_s3(request.panel_imageurl)
        image_info = get_image_info(image_data, request.panel_imageurl)

        # AI ë¶„ì„ ìˆ˜í–‰
        analysis_result = await damage_analyzer.analyze_damage(image_data)
        processing_time = time.time() - start_time

        # ì‘ë‹µ êµ¬ì„±
        response = DamageAnalysisResponse(
            panel_id=request.panel_id,
            user_id=request.user_id,
            image_info=image_info,
            damage_analysis=analysis_result["damage_analysis"],
            business_assessment=analysis_result["business_assessment"],
            detection_details=analysis_result["detection_details"],
            confidence_score=analysis_result["confidence_score"],
            processing_time_seconds=processing_time
        )

        log_api_request("POST", "/api/damage-analysis/analyze",
                       str(request.user_id), request.panel_id, processing_time)

        return response

    except AIServiceException:
        raise
    except Exception as e:
        logger.error(f"ì†ìƒ ë¶„ì„ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")


@app.get("/api/performance-analysis/health")
async def performance_health_check():
    """ì„±ëŠ¥ ì˜ˆì¸¡ ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬"""
    health_info = _check_service_health(performance_analyzer, "PerformanceAnalyzer")

    return {
        **health_info,
        "service": "performance-analysis",
        "version": settings.app_version
    }


@app.post("/api/performance-analysis/report", response_model=PerformanceReportResponse)
async def generate_performance_report_endpoint(request: PanelRequest):
    """íƒœì–‘ê´‘ íŒ¨ë„ ì„±ëŠ¥ ì˜ˆì¸¡ ë° PDF ë¦¬í¬íŠ¸ ìƒì„±"""
    start_time = time.time()

    # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    if performance_analyzer is None or not performance_analyzer.is_loaded():
        raise ModelNotLoadedException("PerformanceAnalyzer", settings.performance_model_path)

    try:
        log_api_request("POST", "/api/performance-analysis/report", request.user_id, request.id)

        # ì„±ëŠ¥ ë¶„ì„ ìˆ˜í–‰
        # í†µí•©ëœ ì„±ëŠ¥ ë¶„ì„ ë° ê³ ê¸‰ ë¦¬í¬íŠ¸ ìƒì„± (ê¸°ì¡´ API ìœ ì§€, í’ˆì§ˆ ê°œì„ )
        analysis_result = await performance_analyzer.analyze_with_report(request)

        processing_time = time.time() - start_time

        response = PerformanceReportResponse(
            user_id=request.user_id,
            address=analysis_result["report_path"],  # ê³ ê¸‰ ë¦¬í¬íŠ¸ ê²½ë¡œ
            created_at=analysis_result["created_at"]  # ReportServiceì—ì„œ ìƒì„±ëœ ì •í™•í•œ ì‹œê°„
        )

        log_api_request("POST", "/api/performance-analysis/report",
                       request.user_id, request.id, processing_time)

        return response

    except AIServiceException:
        raise
    except Exception as e:
        logger.error(f"ì„±ëŠ¥ ë¶„ì„ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì„±ëŠ¥ ë¶„ì„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")


@app.post("/api/performance-analysis/analyze", response_model=PerformanceReportDetailResponse)
async def analyze_performance_detailed(request: PanelRequest):
    """ìƒì„¸í•œ ì„±ëŠ¥ ë¶„ì„ (PDF ìƒì„± ì—†ì´ ë¶„ì„ ê²°ê³¼ë§Œ ë°˜í™˜)"""
    start_time = time.time()

    # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    if performance_analyzer is None or not performance_analyzer.is_loaded():
        raise ModelNotLoadedException("PerformanceAnalyzer", settings.performance_model_path)

    try:
        log_api_request("POST", "/api/performance-analysis/analyze", request.user_id, request.id)

        # ì„±ëŠ¥ ë¶„ì„ ìˆ˜í–‰
        analysis_result = await performance_analyzer.analyze_performance(request)
        processing_time = time.time() - start_time

        # ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼ êµ¬ì„±
        performance_analysis = PerformanceAnalysisResult(
            predicted_generation=analysis_result["predicted_generation"],
            actual_generation=analysis_result["actual_generation"],
            performance_ratio=analysis_result["performance_ratio"],
            status=analysis_result["status"],
            lifespan_months=analysis_result.get("lifespan_months"),
            estimated_cost=analysis_result.get("estimated_cost")
        )

        response = PerformanceReportDetailResponse(
            user_id=request.user_id,
            panel_id=request.id,
            performance_analysis=performance_analysis,
            report_path="",
            created_at=datetime.now().isoformat(),
            processing_time_seconds=processing_time,
            panel_info=analysis_result.get("panel_info", {}),
            environmental_data=analysis_result.get("environmental_data", {})
        )

        log_api_request("POST", "/api/performance-analysis/analyze",
                       request.user_id, request.id, processing_time)

        return response

    except AIServiceException:
        raise
    except Exception as e:
        logger.error(f"ìƒì„¸ ì„±ëŠ¥ ë¶„ì„ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ìƒì„¸ ë¶„ì„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")


if __name__ == "__main__":
    uvicorn.run(
        "app.main:app",
        host=settings.host,
        port=settings.port,
        reload=settings.is_development,
        log_level=settings.log_level.lower()
    )